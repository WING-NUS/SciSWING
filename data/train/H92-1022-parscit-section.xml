<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010483">
<title confidence="0.990719">
A SIMPLE RULE-BASED PART OF SPEECH TAGGER
</title>
<author confidence="0.998123">
Eric Brill *
</author>
<affiliation confidence="0.999049">
Department of Computer Science
University of Pennsylvania
</affiliation>
<address confidence="0.467045">
Philadelphia, Pennsylvania 19104
</address>
<email confidence="0.861068">
brillOunagi.cis.upenn.edu
</email>
<sectionHeader confidence="0.985331" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.998973105263158">
Automatic part of speech tagging is an area of natural lan-
guage processing where statistical techniques have been more
successful than rule-based methods. In this paper, we present
a simple rule-based part of speech tagger which automati-
cally acquires its rules and tags with accuracy comparable
to stochastic taggers. The rule-based tagger has many ad-
vantages over these taggers, including: a vast reduction in
stored information required, the perspicuity of a small set
of meaningful rules, ease of finding and implementing im-
provements to the tagger, and better portability from one
tag set, corpus genre or language to another. Perhaps the
biggest contribution of this work is in demonstrating that
the stochastic method is not the only viable method for part
of speech tagging. The fact that a simple rule-based tagger
that automatically learns its rules can perform so well should
offer encouragement for researchers to further explore rule-
based tagging, searching for a better and more expressive
set of rule templates and other variations on the simple but
effective theme described below.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999960384615385">
There has been a dramatic increase in the application of
probabilistic models to natural language processing over
the last few years. The appeal of stochastic techniques
over traditional rule-based techniques comes from the
ease with which the necessary statistics can be automat-
ically acquired and the fact that very little handcrafted
knowledge need be built into the system. In contrast,
the rules in rule-based systems are usually difficult to
construct and are typically not very robust.
One area in which the statistical approach has done par-
ticularly well is automatic part of speech tagging, as-
signing each word in an input sentence its proper part of
speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have
</bodyText>
<note confidence="0.858530333333333">
*A version of this paper appears in Proceedings of the Third
Conference on Applied Computational Linguistics (ACL), Trento,
Italy, 1992. Used by permission of the Association for Computa-
</note>
<footnote confidence="0.881879857142857">
tional Linguistics; copies of the publication from which this ma-
terial is derived can can be obtained from Dr. Donald E. Walker
(ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morris-
town, NJ 07960-1910, USA. The author would like to thank Mitch
Marcus and Rich Pito for valuable input. This work was supported
by DARPA and AFOSR jointly under grant No. AFOSR-90-0066,
and by ARO grant No. DAAL 03-89-00031 PRI.
</footnote>
<bodyText confidence="0.99982021875">
obtained a high degree of accuracy without performing
any syntactic analysis on the input. These stochastic
part of speech taggers make use of a Markov model
which captures lexical and contextual information. The
parameters of the model can be estimated from tagged
[1, 3, 4, 6, 12] or untagged [2, 9, 11] text. Once the
parameters of the model are estimated, a sentence can
then be automatically tagged by assigning it the tag se-
quence which is assigned the highest probability by the
model. Performance is often enhanced with the aid of
various higher level pre- and postprocessing procedures
or by manually tuning the model.
A number of rule-based taggers have been built [10, 7, 8].
[10] and [7] both have error rates substantially higher
than state of the art stochastic taggers. [8] disam-
biguates words within a deterministic parser. We wanted
to determine whether a simple rule-based tagger with-
out any knowledge of syntax can perform as well as a
stochastic tagger, or if part of speech tagging really is a
domain to which stochastic techniques are better suited.
In this paper we describe a rule-based tagger which per-
forms as well as taggers based upon probabilistic models.
The rule-based tagger overcomes the limitations common
in rule-based approaches to language processing: it is
robust, and the rules are automatically acquired. In ad-
dition, the tagger has many advantages over stochastic
taggers, including: a vast reduction in stored informa-
tion required, the perspicuity of a small set of meaningful
rules as opposed to the large tables of statistics needed
for stochastic taggers, ease of finding and implementing
improvements to the tagger, and better portability from
one tag set or corpus genre to another.
</bodyText>
<sectionHeader confidence="0.997156" genericHeader="method">
2. THE TAGGER
</sectionHeader>
<bodyText confidence="0.998621333333333">
The tagger works by automatically recognizing and rem-
edying its weaknesses, thereby incrementally improving
its performance. The tagger initially tags by assigning
each word its most likely tag, estimated by examining a
large tagged corpus, without regard to context. In both
sentences below, run would be tagged as a verb:
</bodyText>
<page confidence="0.997381">
112
</page>
<bodyText confidence="0.9980939">
The run lasted thirty minutes.
We run three miles every day.
The initial tagger has two procedures built in to improve
performance; both make use of no contextual informa-
tion. One procedure is provided with information that
words that were not in the training corpus and are cap-
italized tend to be proper nouns, and attempts to fix
tagging mistakes accordingly. This information could be
acquired automatically (see below), but is prespecified
in the current implementation. In addition, there is a
procedure which attempts to tag words not seen in the
training corpus by assigning such words the tag most
common for words ending in the same three letters. For
example, blahblahous would be tagged as an adjective,
because this is the most common tag for words ending
in ous. This information is derived automatically from
the training corpus.
This very simple algorithm has an error rate of about
7.9% when trained on 90% of the tagged Brown Corpusl
[5], and tested on a separate 5% of the corpus.&apos; Training
consists of compiling a list of the most common tag for
each word in the training corpus.
The tagger then acquires patches to improve its perfor-
mance. Patch templates are of the form:
have been tagged with tagb in the patch corpus. Next, for
each error triple, it is determined which instantiation of
a template from the prespecified set of patch templates
results in the greatest error reduction. Currently, the
patch templates are:
Change tag a to tag b when:
</bodyText>
<listItem confidence="0.977112111111111">
1. The preceding (following) word is tagged z.
2. The word two before (after) is tagged z.
3. One of the two preceding (following) words is tagged
z.
4. One of the three preceding (following) words is
tagged z.
5. The preceding word is tagged z and the following
word is tagged w.
6. The preceding (following) word is tagged z and the
word two before (after) is tagged w.
7. The current word is (is not) capitalized.
8. The previous word is (is not) capitalized.
• If a word is tagged a and it is in context C, then
change that tag to b, or
• If a word is tagged a and it has lexical property P,
then change that tag to b, or
• If a word is tagged a and a word in region R has
lexical property P, then change that tag to b.
</listItem>
<bodyText confidence="0.941162527777778">
The initial tagger was trained on 90% of the corpus (the
training corpus). 5% was held back to be used for the
patch acquisition procedure (the patch corpus) and 5%
for testing. Once the initial tagger is trained, it is used to
tag the patch corpus. A list of tagging errors is compiled
by comparing the output of the tagger to the correct
tagging of the patch corpus. This list consists of triples
&lt; taga , tag b, number &gt;, indicating the number of times
the tagger mistagged a word with tag° when it should
The Brown Corpus contains about 1.1 million words from a
variety of genres of written English. There are 192 tags in the tag
set, 96 of which occur more than one hundred times in the corpus.
2The test set contained text from all genres in the Brown
Corpus.
For each error triple &lt; tago,tagb,number &gt; and patch,
we compute the reduction in error which results from
applying the patch to remedy the mistagging of a word
as taga when it should have been tagged tam,. We then
compute the number of new errors caused by applying
the patch; that is, the number of times the patch results
in a word being tagged as tagb when it should be tagged
Jaya. The net improvement is calculated by subtracting
the latter value from the former.
For example, when the initial tagger tags the patch cor-
pus, it mistags 159 words as verbs when they should be
nouns. If the patch change the tag from verb to noun if
one of the two preceding words is tagged as a determiner
is applied, it corrects 98 of the 159 errors. However,
it results in an additional 18 errors from changing tags
which really should have been verb to noun. This patch
results in a net decrease of 80 errors on the patch corpus.
The patch which results in the greatest improvement to
the patch corpus is added to the list of patches. The
patch is then applied in order to improve the tagging of
the patch corpus, and the patch acquisition procedure
continues.
</bodyText>
<page confidence="0.996513">
113
</page>
<bodyText confidence="0.994042">
The first ten patches found by the system are listed
below3.
</bodyText>
<listItem confidence="0.9997829">
(1) TO IN NEXT-TAG AT
(2) VBN VBD PREV-WORD-IS-CAP YES
(3) VBD VBN PREV-1-0R-2-0R-3-TAG HVD
(4) VB NN PREV-1-0R-2-TAG AT
(5) NN VB PREV-TAG TO
(6) TO IN NEXT-WORD-IS-CAP YES
(7) NN VB PREY-TAG MD
(8) PPS PPO NEXT-TAG.
(9) VBN VBD PREY-TAG PPS
(10) NP NN CURRENT-WORD-IS-CAP NO
</listItem>
<bodyText confidence="0.999950307692308">
The first patch states that if a word is tagged TO and the
following word is tagged AT, then switch the tag from
TO to IN. This is because a noun phrase is much more
likely to immediately follow a preposition than to im-
mediately follow infinitive TO. The second patch states
that a tag should be switched from VBN to VBD if the
preceding word is capitalized. This patch arises from two
facts: the past verb tag is more likely than the past par-
ticiple verb tag after a proper noun, and is also the more
likely tag for the second word of the sentence.4 The third
patch states that VBD should be changed to VBN if
any of the preceding three words are tagged HVD.
Once the list of patches has been acquired, new text
can be tagged as follows. First, tag the text using the
basic lexical tagger. Next, apply each patch in turn to
the corpus to decrease the error rate. A patch which
changes the tagging of a word from a to b only applies
if the word has been tagged b somewhere in the training
corpus.
Note that one need not be too careful when constructing
the list of patch templates. Adding a bad template to the
list will not worsen performance. If a template is bad,
then no rules which are instantiations of that template
will appear in the final list of patches learned by the
tagger. This makes it easy to experiment with extensions
to the tagger.
</bodyText>
<footnote confidence="0.9798875">
3AT = article, HVD = had, IN = preposition, MD = modal,
NN = sing. noun, NP = proper noun, PPS = 3rd sing. nom.
pronoun, PPO obj. personal pronoun, TO = infinitive to, VB
= verb, VBN = past part. verb, VBD = past verb.
4Both the first word of a sentence and proper nouns are
capitalized.
</footnote>
<note confidence="0.702395">
Patch Application and Error Reduction
</note>
<subsectionHeader confidence="0.314569">
Number of Patches
</subsectionHeader>
<sectionHeader confidence="0.999557" genericHeader="evaluation">
3. RESULTS
</sectionHeader>
<bodyText confidence="0.99984615">
The tagger was tested on 5% of the Brown Corpus in-
cluding sections from every genre. First, the test corpus
was tagged by the simple lexical tagger. Next, each of
the patches was in turn applied to the corpus. Below is a
graph showing the improvement in accuracy from apply-
ing patches. It is significant that with only 71 patches,
an error rate of 5.1% was obtained5. Of the 71 patches,
66 resulted in a reduction in the number of errors in the
test corpus, 3 resulted in no net change, and 2 resulted
in a higher number of errors. Almost all patches which
were effective on the training corpus were also effective
on the test corpus.
Unfortunately, it is difficult to compare our results with
other published results. In [12], an error rate of 3-4%
on one domain, Wall Street Journal articles and 5.6%
on another domain, texts on terrorism in Latin Amer-
ican countries, is quoted. However, both the domains
and the tag set are different from what we use. [1] re-
ports an accuracy of &quot;95-99% correct, depending on the
definition of correct&quot;. We implemented a version of the
</bodyText>
<footnote confidence="0.873824">
5We ran the experiment three times. Each time we divided the
corpus into training, patch and test sets in a different way. All
three runs gave an error rate of 5%.
</footnote>
<page confidence="0.998259">
114
</page>
<bodyText confidence="0.99997536">
algorithm described in [1] which did not make use of a
dictionary to extend its lexical knowledge. When trained
and tested on the same samples used in our experiment,
we found the error rate to be about 4.5%. [3] quotes
a 4% error rate when testing and training on the same
text. [6] reports an accuracy of 96-97%. Their proba-
bilistic tagger has been augmented with a handcrafted
procedure to pretag problematic &quot;idioms&quot;. This proce-
dure, which requires that a list of idioms be laboriously
created by hand, contributes 3% toward the accuracy of
their tagger, according to [3]. The idiom list would have
to be rewritten if one wished to use this tagger for a
different tag set or a different corpus. It is interesting
to note that the information contained in the idiom list
can be automatically acquired by the rule-based tagger.
For example, their tagger had difficulty tagging as old
as. An explicit rule was written to pretag as old as with
the proper tags. According to the tagging scheme of the
Brown Corpus, the first as should be tagged as a quali-
fier, and the second as a subordinating conjunction. In
the rule-based tagger, the most common tag for as is
subordinating conjunction. So initially, the second as is
tagged correctly and the first as is tagged incorrectly. To
remedy this, the system acquires the patch: if the cur-
rent word is tagged as a subordinating conjunction, and
so is the word two positions ahead, then change the tag of
the current word to qualifier.&apos; The rule-based tagger has
automatically learned how to properly tag this &quot;idiom.&quot;
Regardless of the precise rankings of the various taggers,
we have demonstrated that a simple rule-based tagger
with very few rules performs on par with stochastic tag-
gers. It should be mentioned that our results were ob-
tained without the use of a dictionary. Incorporating a
large dictionary into the system would improve perfor-
mance in two ways. First, it would increase the accuracy
in tagging words not seen in the training corpus, since
part of speech information for some words not appearing
in the training corpus can be obtained from the dictio-
nary. Second, it would increase the error reduction re-
sulting from applying patches. When a patch indicates
that a word should be tagged with tagb instead of taga,
the tag is only switched if the word was tagged with tagb
somewhere in the training corpus. Using a dictionary
would provide more accurate knowledge about the set
of permissible part of speech tags for a particular word.
We plan to incorporate a dictionary into the tagger in
the future.
As an estimate of the improvement possible by using
a dictionary, we ran two experiments where all words
were known by the system. First, the Brown Corpus
</bodyText>
<footnote confidence="0.7930135">
6This was one of the 71 patches acquired by the rule-based
tagger.
</footnote>
<bodyText confidence="0.999975785714286">
was divided into a training corpus of about one million
words, a patch corpus of about 65,000 words and a test
corpus of about 65,000 words. Patches were acquired
as described above. When tested on the test corpus,
with lexical information derived solely from the training
corpus, the error rate was 5%. Next, the same patches
weie used, but lexical information was gathered from
the entire Brown Corpus. This reduced the error rate to
4.1%. Finally, the same experiment was run with lexical
information gathered solely from the test corpus. This
resulted in a 3.5% error rate. Note that the patches used
in the two experiments with no unknown words were
not the optimal patches for these tests, since they were
derived from a corpus that contained unknown words.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="conclusions">
4. CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999517617647059">
We have presented a simple rule-based part of speech
tagger which performs as well as existing stochastic tag-
gers, but has significant advantages over these taggers.
The tagger is extremely portable. Many of the higher
level procedures used to improve the performance of
stochastic taggers would not readily transfer over to a
different tag set or genre, and certainly would not trans-
fer over to a different language. Everything except for
the proper noun discovery procedure is automatically ac-
quired by the rule-based tagger7, making it much more
portable than a stochastic tagger. If the tagger were
trained on a different corpus, a different set of patches
suitable for that corpus would be found automatically.
Large tables of statistics are not needed for the rule-
based tagger. In a stochastic tagger, tens of thousands
of lines of statistical information are needed to capture
contextual information. This information is usually a ta-
ble of trigram statistics, indicating for all tags taga,tagb
and tags the probability that tag, follows taga and tagb.
In the rule-based tagger, contextual information is cap-
tured in fewer than eighty rules. This makes for a much
more perspicuous tagger, aiding in better understanding
and simplifying further development of the tagger. Con-
textual information is expressed in a much more compact
and understandable form. As can be seen from compar-
ing error rates, this compact representation of contextual
information is just as effective as the information hidden
in the large tables of contextual probabilities.
Perhaps the biggest contribution of this work is in
demonstrating that the stochastic method is not the only
viable approach for part of speech tagging. The fact that
the simple rule-based tagger can perform so well should
offer encouragement for researchers to further explore
rule-based tagging, searching for a better and more ex-
</bodyText>
<footnote confidence="0.955567">
7And even this could be learned by the tagger.
</footnote>
<page confidence="0.998351">
115
</page>
<bodyText confidence="0.9997105">
pressive set of patch templates and other variations on
this simple but effective theme.
</bodyText>
<sectionHeader confidence="0.998462" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999982292682927">
1. Church, K. A Stochastic Parts Program and Noun
Phrase Parser for Unrestricted Text. In Proceedings of
the Second Conference on Applied Natural Language
Processing, ACL, 136-143, 1988.
2. Cutting, D., Kupiec, J., Pederson, J. and Sibun, P. A
Practical Part-of-Speech Tagger. In Proceedings of the
Third Conference on Applied Natural Language Process-
ing, ACL, 1992.
3. DeRose, S.J. Grammatical Category Disambiguation by
Statistical Optimization. Computational Linguistics 14:
31-39, 1988.
4. Deroualt, A. and Merialdo, B. Natural language mod-
eling for phoneme-to-text transcription. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, Vol.
PAMI-8, No. 6, 742-749, 1986.
5. Francis, W. Nelson and Kutera, Henry, Frequency anal-
ysis of English usage. Lexicon and grammar. Houghton
Mifflin, Boston, 1982.
6. Garside, R., Leech, G. Sz Sampson, G. The Computa-
tional Analysis of English: A Corpus-Based Approach.
Longman: London, 1987.
7. Green, B. and Rubin, G. Automated Grammatical Tag-
ging of English. Department of Linguistics, Brown Uni-
versity, 1971.
8. Hindle, D. Acquiring disambiguation rules from text.
Proceedings of the 27th Annual Meeting of the Associ-
ation for Computational Linguistics, 1989.
9. Jelinek, F. Markov source modeling of text generation.
In J. K. Skwirzinsld, ed., Impact of Processing Tech-
niques on Communication, Dordrecht, 1985.
10. Klein, S. and Simmons, R.F. A Computational Ap-
proach to Grammatical Coding of English Words. JA CM
10: 334-47. 1963.
11. Kupiec, J. Augmenting a hidden Markov model for
phrase-dependent word tagging. In Proceedings of the
DARPA Speech and Natural Language Workshop, Mor-
gan Kaufmann, 1989.
12. Meteer, M., Schwartz, R., and Weischedel, R. Empirical
Studies in Part of Speech Labelling, Proceedings of the
DARPA Speech and Natural Language Workshop, Mor-
gan Kaufmann, 1991.
</reference>
<page confidence="0.999027">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.987044">
<title confidence="0.999679">A SIMPLE RULE-BASED PART OF SPEECH TAGGER</title>
<author confidence="0.996869">Eric Brill</author>
<affiliation confidence="0.9998905">Department of Computer Science University of Pennsylvania</affiliation>
<address confidence="0.9995">Philadelphia, Pennsylvania 19104</address>
<email confidence="0.999416">brillOunagi.cis.upenn.edu</email>
<abstract confidence="0.9995791">Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods. In this paper, we present a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers. The rule-based tagger has many advantages over these taggers, including: a vast reduction in stored information required, the perspicuity of a small set of meaningful rules, ease of finding and implementing improvements to the tagger, and better portability from one tag set, corpus genre or language to another. Perhaps the biggest contribution of this work is in demonstrating that the stochastic method is not the only viable method for part of speech tagging. The fact that a simple rule-based tagger that automatically learns its rules can perform so well should offer encouragement for researchers to further explore rulebased tagging, searching for a better and more expressive set of rule templates and other variations on the simple but effective theme described below.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text.</title>
<date>1988</date>
<booktitle>In Proceedings of the Second Conference on Applied Natural Language Processing, ACL,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
<context position="11809" citStr="[1]" startWordPosition="2060" endWordPosition="2060">s obtained5. Of the 71 patches, 66 resulted in a reduction in the number of errors in the test corpus, 3 resulted in no net change, and 2 resulted in a higher number of errors. Almost all patches which were effective on the training corpus were also effective on the test corpus. Unfortunately, it is difficult to compare our results with other published results. In [12], an error rate of 3-4% on one domain, Wall Street Journal articles and 5.6% on another domain, texts on terrorism in Latin American countries, is quoted. However, both the domains and the tag set are different from what we use. [1] reports an accuracy of &quot;95-99% correct, depending on the definition of correct&quot;. We implemented a version of the 5We ran the experiment three times. Each time we divided the corpus into training, patch and test sets in a different way. All three runs gave an error rate of 5%. 114 algorithm described in [1] which did not make use of a dictionary to extend its lexical knowledge. When trained and tested on the same samples used in our experiment, we found the error rate to be about 4.5%. [3] quotes a 4% error rate when testing and training on the same text. [6] reports an accuracy of 96-97%. The</context>
</contexts>
<marker>1.</marker>
<rawString>Church, K. A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text. In Proceedings of the Second Conference on Applied Natural Language Processing, ACL, 136-143, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cutting</author>
<author>J Kupiec</author>
<author>J Pederson</author>
<author>P Sibun</author>
</authors>
<title>A Practical Part-of-Speech Tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing, ACL,</booktitle>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
</contexts>
<marker>2.</marker>
<rawString>Cutting, D., Kupiec, J., Pederson, J. and Sibun, P. A Practical Part-of-Speech Tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, ACL, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J DeRose</author>
</authors>
<title>Grammatical Category Disambiguation by Statistical Optimization.</title>
<date>1988</date>
<journal>Computational Linguistics</journal>
<volume>14</volume>
<pages>31--39</pages>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
<context position="12303" citStr="[3]" startWordPosition="2150" endWordPosition="2150"> American countries, is quoted. However, both the domains and the tag set are different from what we use. [1] reports an accuracy of &quot;95-99% correct, depending on the definition of correct&quot;. We implemented a version of the 5We ran the experiment three times. Each time we divided the corpus into training, patch and test sets in a different way. All three runs gave an error rate of 5%. 114 algorithm described in [1] which did not make use of a dictionary to extend its lexical knowledge. When trained and tested on the same samples used in our experiment, we found the error rate to be about 4.5%. [3] quotes a 4% error rate when testing and training on the same text. [6] reports an accuracy of 96-97%. Their probabilistic tagger has been augmented with a handcrafted procedure to pretag problematic &quot;idioms&quot;. This procedure, which requires that a list of idioms be laboriously created by hand, contributes 3% toward the accuracy of their tagger, according to [3]. The idiom list would have to be rewritten if one wished to use this tagger for a different tag set or a different corpus. It is interesting to note that the information contained in the idiom list can be automatically acquired by the r</context>
</contexts>
<marker>3.</marker>
<rawString>DeRose, S.J. Grammatical Category Disambiguation by Statistical Optimization. Computational Linguistics 14: 31-39, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Deroualt</author>
<author>B Merialdo</author>
</authors>
<title>Natural language modeling for phoneme-to-text transcription.</title>
<date>1986</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>8</volume>
<pages>742--749</pages>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
</contexts>
<marker>4.</marker>
<rawString>Deroualt, A. and Merialdo, B. Natural language modeling for phoneme-to-text transcription. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-8, No. 6, 742-749, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
<author>Henry Kutera</author>
</authors>
<title>Frequency analysis of English usage. Lexicon and grammar.</title>
<date>1982</date>
<location>Houghton Mifflin, Boston,</location>
<contexts>
<context position="5645" citStr="[5]" startWordPosition="910" endWordPosition="910">cordingly. This information could be acquired automatically (see below), but is prespecified in the current implementation. In addition, there is a procedure which attempts to tag words not seen in the training corpus by assigning such words the tag most common for words ending in the same three letters. For example, blahblahous would be tagged as an adjective, because this is the most common tag for words ending in ous. This information is derived automatically from the training corpus. This very simple algorithm has an error rate of about 7.9% when trained on 90% of the tagged Brown Corpusl [5], and tested on a separate 5% of the corpus.&apos; Training consists of compiling a list of the most common tag for each word in the training corpus. The tagger then acquires patches to improve its performance. Patch templates are of the form: have been tagged with tagb in the patch corpus. Next, for each error triple, it is determined which instantiation of a template from the prespecified set of patch templates results in the greatest error reduction. Currently, the patch templates are: Change tag a to tag b when: 1. The preceding (following) word is tagged z. 2. The word two before (after) is ta</context>
</contexts>
<marker>5.</marker>
<rawString>Francis, W. Nelson and Kutera, Henry, Frequency analysis of English usage. Lexicon and grammar. Houghton Mifflin, Boston, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Garside</author>
<author>G Sz Sampson Leech</author>
<author>G</author>
</authors>
<title>The Computational Analysis of English: A Corpus-Based Approach.</title>
<date>1987</date>
<location>Longman: London,</location>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
<context position="12374" citStr="[6]" startWordPosition="2164" endWordPosition="2164">et are different from what we use. [1] reports an accuracy of &quot;95-99% correct, depending on the definition of correct&quot;. We implemented a version of the 5We ran the experiment three times. Each time we divided the corpus into training, patch and test sets in a different way. All three runs gave an error rate of 5%. 114 algorithm described in [1] which did not make use of a dictionary to extend its lexical knowledge. When trained and tested on the same samples used in our experiment, we found the error rate to be about 4.5%. [3] quotes a 4% error rate when testing and training on the same text. [6] reports an accuracy of 96-97%. Their probabilistic tagger has been augmented with a handcrafted procedure to pretag problematic &quot;idioms&quot;. This procedure, which requires that a list of idioms be laboriously created by hand, contributes 3% toward the accuracy of their tagger, according to [3]. The idiom list would have to be rewritten if one wished to use this tagger for a different tag set or a different corpus. It is interesting to note that the information contained in the idiom list can be automatically acquired by the rule-based tagger. For example, their tagger had difficulty tagging as o</context>
</contexts>
<marker>6.</marker>
<rawString>Garside, R., Leech, G. Sz Sampson, G. The Computational Analysis of English: A Corpus-Based Approach. Longman: London, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Green</author>
<author>G Rubin</author>
</authors>
<title>Automated Grammatical Tagging of</title>
<date>1971</date>
<institution>English. Department of Linguistics, Brown University,</institution>
<contexts>
<context position="3304" citStr="[10, 7, 8]" startWordPosition="527" endWordPosition="529">s on the input. These stochastic part of speech taggers make use of a Markov model which captures lexical and contextual information. The parameters of the model can be estimated from tagged [1, 3, 4, 6, 12] or untagged [2, 9, 11] text. Once the parameters of the model are estimated, a sentence can then be automatically tagged by assigning it the tag sequence which is assigned the highest probability by the model. Performance is often enhanced with the aid of various higher level pre- and postprocessing procedures or by manually tuning the model. A number of rule-based taggers have been built [10, 7, 8]. [10] and [7] both have error rates substantially higher than state of the art stochastic taggers. [8] disambiguates words within a deterministic parser. We wanted to determine whether a simple rule-based tagger without any knowledge of syntax can perform as well as a stochastic tagger, or if part of speech tagging really is a domain to which stochastic techniques are better suited. In this paper we describe a rule-based tagger which performs as well as taggers based upon probabilistic models. The rule-based tagger overcomes the limitations common in rule-based approaches to language processi</context>
</contexts>
<marker>7.</marker>
<rawString>Green, B. and Rubin, G. Automated Grammatical Tagging of English. Department of Linguistics, Brown University, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Acquiring disambiguation rules from text.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="3304" citStr="[10, 7, 8]" startWordPosition="527" endWordPosition="529">s on the input. These stochastic part of speech taggers make use of a Markov model which captures lexical and contextual information. The parameters of the model can be estimated from tagged [1, 3, 4, 6, 12] or untagged [2, 9, 11] text. Once the parameters of the model are estimated, a sentence can then be automatically tagged by assigning it the tag sequence which is assigned the highest probability by the model. Performance is often enhanced with the aid of various higher level pre- and postprocessing procedures or by manually tuning the model. A number of rule-based taggers have been built [10, 7, 8]. [10] and [7] both have error rates substantially higher than state of the art stochastic taggers. [8] disambiguates words within a deterministic parser. We wanted to determine whether a simple rule-based tagger without any knowledge of syntax can perform as well as a stochastic tagger, or if part of speech tagging really is a domain to which stochastic techniques are better suited. In this paper we describe a rule-based tagger which performs as well as taggers based upon probabilistic models. The rule-based tagger overcomes the limitations common in rule-based approaches to language processi</context>
</contexts>
<marker>8.</marker>
<rawString>Hindle, D. Acquiring disambiguation rules from text. Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Markov source modeling of text generation.</title>
<date>1985</date>
<booktitle>Impact of Processing Techniques on Communication,</booktitle>
<editor>In J. K. Skwirzinsld, ed.,</editor>
<location>Dordrecht,</location>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
</contexts>
<marker>9.</marker>
<rawString>Jelinek, F. Markov source modeling of text generation. In J. K. Skwirzinsld, ed., Impact of Processing Techniques on Communication, Dordrecht, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Klein</author>
<author>R F Simmons</author>
</authors>
<title>A Computational Approach to Grammatical Coding of English Words.</title>
<date>1963</date>
<journal>JA CM</journal>
<volume>10</volume>
<pages>334--47</pages>
<contexts>
<context position="3304" citStr="[10, 7, 8]" startWordPosition="527" endWordPosition="529">s on the input. These stochastic part of speech taggers make use of a Markov model which captures lexical and contextual information. The parameters of the model can be estimated from tagged [1, 3, 4, 6, 12] or untagged [2, 9, 11] text. Once the parameters of the model are estimated, a sentence can then be automatically tagged by assigning it the tag sequence which is assigned the highest probability by the model. Performance is often enhanced with the aid of various higher level pre- and postprocessing procedures or by manually tuning the model. A number of rule-based taggers have been built [10, 7, 8]. [10] and [7] both have error rates substantially higher than state of the art stochastic taggers. [8] disambiguates words within a deterministic parser. We wanted to determine whether a simple rule-based tagger without any knowledge of syntax can perform as well as a stochastic tagger, or if part of speech tagging really is a domain to which stochastic techniques are better suited. In this paper we describe a rule-based tagger which performs as well as taggers based upon probabilistic models. The rule-based tagger overcomes the limitations common in rule-based approaches to language processi</context>
</contexts>
<marker>10.</marker>
<rawString>Klein, S. and Simmons, R.F. A Computational Approach to Grammatical Coding of English Words. JA CM 10: 334-47. 1963.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
</authors>
<title>Augmenting a hidden Markov model for phrase-dependent word tagging.</title>
<date>1989</date>
<booktitle>In Proceedings of the DARPA Speech and Natural Language Workshop,</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
</contexts>
<marker>11.</marker>
<rawString>Kupiec, J. Augmenting a hidden Markov model for phrase-dependent word tagging. In Proceedings of the DARPA Speech and Natural Language Workshop, Morgan Kaufmann, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Meteer</author>
<author>R Schwartz</author>
<author>R Weischedel</author>
</authors>
<title>Empirical Studies in Part of Speech Labelling,</title>
<date>1991</date>
<booktitle>Proceedings of the DARPA Speech and Natural Language Workshop,</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="1988" citStr="[1, 2, 3, 4, 6, 9, 11, 12]" startWordPosition="304" endWordPosition="311">tic models to natural language processing over the last few years. The appeal of stochastic techniques over traditional rule-based techniques comes from the ease with which the necessary statistics can be automatically acquired and the fact that very little handcrafted knowledge need be built into the system. In contrast, the rules in rule-based systems are usually difficult to construct and are typically not very robust. One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [1, 2, 3, 4, 6, 9, 11, 12]. Stochastic taggers have *A version of this paper appears in Proceedings of the Third Conference on Applied Computational Linguistics (ACL), Trento, Italy, 1992. Used by permission of the Association for Computational Linguistics; copies of the publication from which this material is derived can can be obtained from Dr. Donald E. Walker (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910, Morristown, NJ 07960-1910, USA. The author would like to thank Mitch Marcus and Rich Pito for valuable input. This work was supported by DARPA and AFOSR jointly under grant No. AFOSR-90-0066, and by ARO g</context>
<context position="11577" citStr="[12]" startWordPosition="2018" endWordPosition="2018">the simple lexical tagger. Next, each of the patches was in turn applied to the corpus. Below is a graph showing the improvement in accuracy from applying patches. It is significant that with only 71 patches, an error rate of 5.1% was obtained5. Of the 71 patches, 66 resulted in a reduction in the number of errors in the test corpus, 3 resulted in no net change, and 2 resulted in a higher number of errors. Almost all patches which were effective on the training corpus were also effective on the test corpus. Unfortunately, it is difficult to compare our results with other published results. In [12], an error rate of 3-4% on one domain, Wall Street Journal articles and 5.6% on another domain, texts on terrorism in Latin American countries, is quoted. However, both the domains and the tag set are different from what we use. [1] reports an accuracy of &quot;95-99% correct, depending on the definition of correct&quot;. We implemented a version of the 5We ran the experiment three times. Each time we divided the corpus into training, patch and test sets in a different way. All three runs gave an error rate of 5%. 114 algorithm described in [1] which did not make use of a dictionary to extend its lexica</context>
</contexts>
<marker>12.</marker>
<rawString>Meteer, M., Schwartz, R., and Weischedel, R. Empirical Studies in Part of Speech Labelling, Proceedings of the DARPA Speech and Natural Language Workshop, Morgan Kaufmann, 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>